{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafío de predicción de retrasos de vuelos\n",
    "\n",
    "## Desafío\n",
    "\n",
    "El problema consiste en predecir la probabilidad de retraso de los vuelos que aterrizan o despegan del aeropuerto de Santiago de Chile (SCL).\n",
    "\n",
    "### Conjunto de datos\n",
    "\n",
    "El conjunto de datos contiene la siguiente información:\n",
    "\n",
    "| Columna       | Descripción                       |   Clase       | Tipo       | Ejemplo             | Commentari      |\n",
    "|---------------|-----------------------------------|---------------|------------|---------------------|-----------------|\n",
    "| **Fecha-I**   | Fecha y hora del vuelo            | Programada    | datetime   | 2017-01-01 23:30:00 |                 |\n",
    "| **Vlo-I**     | Número de vuelo                   | Programada    | string     | 226                 |                 |\n",
    "| **Ori-I**     | Código de la ciudad de origen     | Programada    | string     | SCEL                |                 |\n",
    "| **Des-I**     | Código de la ciudad de destino    | Programada    | string     | KMIA                |                 |\n",
    "| **Emp-I**     | Código de la aerolínea            | Programada    | string     | AAL                 |                 |\n",
    "| **Fecha-O**   | Fecha y hora del vuelo            | Operación     | datetime   | 2017-01-01 23:33:00 |                 |\n",
    "| **Vlo-O**     | Número de vuelo                   | Operación     | string     | 226                 |                 |\n",
    "| **Ori-O**     | Código de la ciudad de origen     | Operación     | string     | SCEL                |                 |\n",
    "| **Des-O**     | Código de la ciudad de destino    | Operación     | string     | KMIA                |                 |\n",
    "| **Emp-O**     | Código de la aerolínea            | Operación     | string     | AAL                 |                 |\n",
    "| **DIA**       | Día del mes                       | Operación     | integer    | 1                   | 1 - 31          |\n",
    "| **MES**       | Número de mes                     | Operación     | integer    | 1                   | 1 - 12          |\n",
    "| **AÑO**       | Año                               | Operación     | integer    | 2017                | 2017 - 2018     |\n",
    "| **DIANOM**    | Día de la semana                  | Operación     | string     | Domingo             | Lunes - Domingo |\n",
    "| **TIPOVUELO** | Tipo de vuelo                     |     -         | string     | I                   | I, N            |\n",
    "| **OPERA**     | Nombre de la aerolínea            | Operación     | string     | American Airlines   |                 |\n",
    "| **SIGLAORI**  | Nombre de la ciudad de origen     |     -         | string     | Santiago            |                 |\n",
    "| **SIGLADES**  | Nombre de la ciudad de destino    |     -         | string     | Miami               |                 |\n",
    "\n",
    "\n",
    "### Características sintéticas\n",
    "\n",
    "Las características sintéticas generadas contienen la siguiente información y están disponibles en el archivo `synthetic_features.csv`:\n",
    "\n",
    "| Columna            | Descripción                                                                                                             | Tipo       | Ejemplo     | Comentario           |\n",
    "|--------------------|-------------------------------------------------------------------------------------------------------------------------|------------|-------------|----------------------|\n",
    "| **temporada_alta** | `1` si el vuelo es entre `15-Dec` y `3-Mar`, o `15-Jul` y `31-Jul`, o `11-Sep` y `30-Sep`, `0` si no.                   | integer    | 1           | 0, 1                 |\n",
    "| **dif_min**        | Diferencia en minutos entre `Fecha-O` y `Fecha-I`.                                                                      | float      | 3           |                      |\n",
    "| **atraso_15**      | `1` si `dif_min > 15`, `0` si no.                                                                                       | integer    | 0           | 0, 1                 |\n",
    "| **periodo_dia**    | Mañana (entre `5:00` y `11:59`), Tarde (entre `12:00` y `18:59`) y Noche (entre `19:00` y `4:59`), en base a `Fecha-I`. | string     | tarde       | mañana, tarde, noche |\n",
    "\n",
    "\n",
    "### Objetivo \n",
    "\n",
    "La columna objetivo (`'atraso_15'`) es una variable binaria, cuyo valor es `1` si el _atraso_ del vuelo es mayor que `15 minutos` y `0` si no.\n",
    "\n",
    "- **NOTA:** La columna `'dif_min'` es utilizada para crear la columna objetivo `'atraso_15'`\n",
    "\n",
    "- **NOTA:** Las columnas `Operación` no están disponibles en el momento de la inferencia.\n",
    "\n",
    "\n",
    "### Consideraciones y comentarios\n",
    "\n",
    "Una vez que se haya realizado el análisis exploratorio y se hayan generado las columnas adicionales, se pueden entrenar distintos modelos para predecir la probabilidad de atraso de un vuelo. Algunas opciones podrían ser modelos de regresión logística, árboles de decisión o redes neuronales. Para elegir el modelo adecuado, es importante evaluar la performance de cada uno de ellos utilizando alguna métrica de evaluación, como la precisión o el AUC (Area Under the Curve). También es importante tener en cuenta la capacidad de interpretabilidad del modelo, es decir, la facilidad para entender cómo toman las decisiones y qué variables son las que más influyen en la predicción.\n",
    "\n",
    "Para evaluar la performance del modelo, se pueden utilizar métricas como la precisión, el recall, el F1-score y el AUC. La precisión mide la proporción de predicciones correctas sobre el total de predicciones realizadas, el recall mide la proporción de casos positivos correctamente identificados sobre el total de casos positivos, el F1-score es la media armónica entre la precisión y el recall y el AUC mide la capacidad del modelo para diferenciar entre casos positivos y negativos.\n",
    "\n",
    "Es importante tener en cuenta que cada métrica puede ser más relevante dependiendo del contexto y de los objetivos del modelo. Por ejemplo, si es importante minimizar los falsos negativos (predicciones incorrectas de casos positivos), el recall puede ser una métrica más adecuada para evaluar el modelo. Por otro lado, si es importante minimizar tanto los falsos positivos como los falsos negativos, el F1-score puede ser una buena opción.\n",
    "\n",
    "Para mejorar la performance del modelo, algunas opciones podrían ser: ajustar los hiperparámetros del modelo, realizar una selección de variables más adecuada, utilizar técnicas de preprocesamiento de datos como la normalización o la estandarización, o complementar con variables externas que puedan ser relevantes para la predicción de atrasos (por ejemplo, datos meteorológicos o de tráfico aéreo).\n",
    "\n",
    "Además, es importante tener en cuenta que es posible que haya desbalance en la distribución de casos positivos y negativos en el dataset, lo que puede afectar la performance del modelo. En este caso, se pueden utilizar técnicas para tratar este desbalance, como el muestreo balanceado o la asignación de pesos a las distintas clases en el proceso de entrenamiento del modelo.\n",
    "\n",
    "Otra opción para mejorar la performance del modelo es realizar una validación cruzada, que consiste en dividir el dataset en distintos conjuntos de entrenamiento y validación y evaluar el modelo en cada uno de ellos. De esta manera, se puede obtener una estimación más precisa de la performance del modelo y detectar posibles problemas de sobreajuste.\n",
    "\n",
    "En resumen, para resolver el problema planteado, es importante realizar un análisis exploratorio de los datos y generar las columnas adicionales solicitadas. Luego, se pueden entrenar distintos modelos y evaluar su performance utilizando métricas como la precisión, el recall, el F1-score y el AUC. Para mejorar la performance del modelo, se pueden ajustar los hiperparámetros, realizar una selección de variables adecuada, utilizar técnicas de preprocesamiento de datos y realizar una validación cruzada. También es importante tener en cuenta el desbalance en la distribución de clases y utilizar técnicas para tratarlo.\n",
    "\n",
    "Otra opción para mejorar la performance del modelo es utilizar técnicas de ensembling, que consisten en combinar el resultado de distintos modelos para obtener una predicción final. Algunas opciones de ensembling son:\n",
    "- Bagging: consiste en entrenar varios modelos de manera independiente y promediar o votar sus predicciones.\n",
    "- Boosting: consiste en entrenar varios modelos de manera secuencial, en los que cada modelo trata de corregir los errores del modelo anterior.\n",
    "- Stacking: consiste en entrenar varios modelos y utilizarlos como features para un modelo final, que realiza la predicción final.\n",
    "\n",
    "Utilizar técnicas de ensembling puede mejorar la performance del modelo al reducir la varianza y el sesgo, ya que cada modelo puede complementar al otro y compensar sus posibles debilidades.\n",
    "\n",
    "Por último, es importante tener en cuenta que la performance del modelo puede depender de la calidad y cantidad de los datos disponibles. Es posible que sea necesario complementar el dataset con variables externas o recopilar más datos para tener una mejor representatividad y poder hacer predicciones más precisas. Además, es importante verificar la integridad y consistencia de los datos y realizar una limpieza y preprocesamiento adecuado antes de entrenar el modelo.\n",
    "\n",
    "En resumen, para resolver el problema de predecir la probabilidad de atraso de vuelos que aterrizan o despegan del aeropuerto de Santiago de Chile, es importante seguir los siguientes pasos:\n",
    "\n",
    "1. Realizar un análisis exploratorio de los datos para conocer la distribución y características de los mismos.\n",
    "2. Generar las columnas adicionales solicitadas utilizando la librería pandas de Python.\n",
    "3. Conocer la tasa de atraso por destino, aerolínea, mes del año, día de la semana, temporada y tipo de vuelo, utilizando gráficos y tablas de frecuencia.\n",
    "4. Entrenar uno o varios modelos de regresión logística, árboles de decisión o redes neuronales, y evaluar su performance utilizando métricas como la precisión, el recall, el F1-score y el AUC.\n",
    "5. Mejorar la performance del modelo ajustando los hiperparámetros, realizando una selección de variables adecuada, utilizando técnicas de preprocesamiento de datos y realizando una validación cruzada.\n",
    "6. Considerar utilizar técnicas de ensembling para combinar el resultado de distintos modelos y obtener una predicción final más precisa.\n",
    "7. Verificar la calidad y cantidad de los datos disponibles y complementar el dataset con variables externas o recopilar más datos si es necesario. Realizar una limpieza y preprocesamiento adecuado de los datos antes de entrenar el modelo.\n",
    "\n",
    "Es importante tener en cuenta que el proceso de modelado y evaluación debe ser iterativo y continuo, ya que puede ser necesario realizar ajustes y mejoras en el modelo para obtener una performance óptima. Además, es importante considerar los objetivos y el contexto en el que se va a utilizar el modelo, ya que esto puede afectar la elección de las métricas de evaluación y las técnicas utilizadas para mejorar la performance.\n",
    "\n",
    "Como continuación del proceso de modelado y evaluación, una vez que se haya seleccionado el modelo que mejor performance tenga, es importante realizar una evaluación final del modelo utilizando un conjunto de datos que no haya sido utilizado para el entrenamiento y la validación. Esto permite tener una estimación más precisa de la performance del modelo en datos \"nuevos\" y verificar si se mantiene la capacidad de generalización del modelo.\n",
    "\n",
    "Además, es importante realizar un monitoreo continuo del modelo una vez que esté en producción, ya que es posible que la performance del mismo vaya deteriorándose con el tiempo debido a cambios en los datos o en el contexto en el que se utiliza. En este caso, puede ser necesario realizar actualizaciones o mejoras en el modelo para mantener su performance óptima.\n",
    "\n",
    "En resumen, el proceso de modelado y evaluación de un modelo de machine learning para predecir la probabilidad de atraso de vuelos incluye: análisis exploratorio de los datos, generación de columnas adicionales, conocimiento de la tasa de atraso por distintas variables, entrenamiento y evaluación de modelos, mejora de la performance del modelo, evaluación final del modelo con datos \"nuevos\" y monitoreo continuo del modelo una vez que esté en producción.\n",
    "\n",
    "Una vez que se haya entrenado y evaluado el modelo para predecir la probabilidad de atraso de vuelos, es importante tener en cuenta que el modelo debe ser utilizado de manera responsable y ética. Esto incluye considerar posibles sesgos o discriminación que puedan estar presentes en los datos o en el modelo, y tomar medidas para minimizarlos o eliminarlos.\n",
    "\n",
    "También es importante tener en cuenta que el modelo es una herramienta y no debe ser utilizado de manera aislada para tomar decisiones, sino que debe ser considerado junto con otros factores y consideraciones relevantes. Además, es importante garantizar la transparencia y explicabilidad del modelo, especialmente en contextos en los que pueda tener impacto en la toma de decisiones o en la vida de las personas.\n",
    "\n",
    "En resumen, es importante utilizar el modelo de manera responsable y ética, considerando posibles sesgos o discriminación y tomando medidas para minimizarlos o eliminarlos, y utilizando el modelo como una herramienta junto con otros factores relevantes. También es importante garantizar la transparencia y explicabilidad del modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías y configuración del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;  // disable vertical scrolling for all cells\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following command to get a link and token to the notebooks\n",
    "# !jupyter notebook list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')  # isort:skip\n",
    "\n",
    "import logging\n",
    "import pprint\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from neuralworks.charts import plot_delay_ratios\n",
    "from neuralworks.constants import get_custom_plotly_figure_size\n",
    "from neuralworks.constants import get_reports_dir_path\n",
    "from neuralworks.constants import get_synthetic_features_file_path\n",
    "from neuralworks.data import create_synthetic_features\n",
    "from neuralworks.data import load_data\n",
    "from neuralworks.data import make_pretty\n",
    "from neuralworks.data import save_synthetic_features_to_file\n",
    "from neuralworks.data import summary\n",
    "from neuralworks.data import TABLE_STYLES\n",
    "from neuralworks.report import generate_profile_report\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    ")\n",
    "\n",
    "# # CONFIGURE NOTEBOOK\n",
    "# # Increase the width of the output of the current notebook\n",
    "# display(Markdown('<style>.container { width:100% !important; }</style>'))\n",
    "# display(HTML('<style>.container { width:100% !important; }</style>'))\n",
    "# display(HTML('<style>.output_result { max-width:100% !important; }</style>'))\n",
    "# display(HTML('<style>.prompt { display:none !important; }</style>'))\n",
    "# display(HTML('<style>.output_subarea { max-width:100% !important; }</style>'))\n",
    "\n",
    "# CONFIGURE MATPLOTLIB\n",
    "# Set the default figure size for matplotlib\n",
    "plt.rcParams['figure.figsize'] = (12, 8)  # (20, 10)\n",
    "\n",
    "# CONFIGURE PANDAS DISPLAY OPTIONS\n",
    "# set the maximum number of rows and columns to display\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "# set the maximum number of characters to display in a column\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "# set the default column width in the DataFrame repr\n",
    "pd.set_option('display.width', 1000)\n",
    "# suppress scientific notation for floats (e.g. 1e-05 -> 0.00001, 1e+05 -> 100000)\n",
    "# display 3 decimal places for floats (e.g. 0.123456 -> 0.123)\n",
    "# do not display decimal places for integers or if the value is 0 (e.g. 0.000 -> 0, 1.000 -> 1)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x if x != 0 and x % 1 else '%.0f' % x)  # pylint: disable=consider-using-f-string\n",
    "\n",
    "# CONFIGURE PANDAS PLOTTING OPTIONS\n",
    "# set the pandas plotting backend\n",
    "# NOTE: 'plotly' plotting backend is not compatible with pandas-profiling\n",
    "# Set pandas plotting backend to 'plotly' (https://plotly.com/python/pandas-backend/) for interactive plots in Jupyter Notebook (https://plotly.com/python/plotly-express/).\n",
    "# NOTE: 'plotly' plotting backend is not compatible with pandas-profiling, so set it back to 'matplotlib' before generating a profile report and then set it back to 'plotly' after generating the profile report.\n",
    "pd.set_option('plotting.backend', 'matplotlib')\n",
    "# pd.options.plotting.backend = 'matplotlib'\n",
    "\n",
    "# CONFIGURE PLOTLY\n",
    "# Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode(connected=False)\n",
    "\n",
    "# CONFIGURE TQDM\n",
    "# Register `pandas.progress_apply` and `pandas.Series.map_apply` with `tqdm`\n",
    "# (can use `tqdm.gui.tqdm`, `tqdm.notebook.tqdm`, optional kwargs, etc.)\n",
    "tqdm.pandas()\n",
    "\n",
    "# CONFIGURE SEABORN\n",
    "# set seaborn style\n",
    "sns.set_theme(style='whitegrid')\n",
    "# sns.set_style(\"darkgrid\")\n",
    "sns.mpl.rc(\"figure\", figsize=(8, 8))  # (20, 10)  # (16, 9)\n",
    "\n",
    "# https://pandas-profiling.ydata.ai/docs/master/pages/getting_started/installation.html\n",
    "\n",
    "CUSTOM_PLOTLY_FIGURE_SIZE = get_custom_plotly_figure_size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = load_data()\n",
    "# summary(df, name='original data')\n",
    "\n",
    "# first rows of the dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de características sintéticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create synthetic features\n",
    "sf = create_synthetic_features(df)\n",
    "# summary(sf, name='synthetic features')\n",
    "\n",
    "# first rows of the dataframe\n",
    "sf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save synthetic features\n",
    "save_synthetic_features_to_file(df=df, overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinación de conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the original and synthetic features\n",
    "data = df.join(sf)\n",
    "\n",
    "# reorder columns to have the target ('atraso_15') at the end of the dataframe\n",
    "# data = data[[c for c in data.columns if c != 'atraso_15'] + ['atraso_15']]\n",
    "data = data.reindex(columns=[c for c in data.columns if c != 'atraso_15'] + ['atraso_15'])\n",
    "\n",
    "# first rows of the dataframe\n",
    "data.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo se distribuyen los datos?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, sería importante realizar un análisis exploratorio para conocer la distribución y características de los datos.\n",
    "\n",
    "Para ello, se pueden realizar gráficos y tablas para visualizar la información y obtener conclusiones.\n",
    "\n",
    "Algunas preguntas que podrían ser interesantes responder son:\n",
    "- ¿Cuántos vuelos hay en el dataset?\n",
    "- ¿Hay una distribución equitativa de vuelos nacionales e internacionales?\n",
    "- ¿Existen aerolíneas que tengan una tasa de atraso mayor a otras?\n",
    "- ¿Hay meses o días de la semana en los que se presentan más atrasos?\n",
    "- ¿Qué porcentaje de vuelos tiene atrasos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(data, name='original data and synthetic features')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios\n",
    "\n",
    "- Llama la atención que la mayoría de los vuelos  (`59.954%`) sean operados por la aerolínea `LAN` (grupo LATAM). Podría ser que la aerolínea `LAN` sea la que más vuelos realiza desde y hacia el aeropuerto de Santiago de Chile, o bien, que ella sea la empresa que esté más interesada en predecir los retrasos de sus vuelos y por lo tanto haya colaborado con la generación de los datos para este desafío (o ambas cosas).\n",
    "\n",
    "- Llama la atención que la mayoría de los vuelos (`81.506%`) tienen un retraso _menor_ a `15` minutos. Por lo tanto, el conjunto de datos está desbalanceado y se debe tener cuidado al evaluar los modelos, ya que, si por ejemplo se utiliza la métrica de _accuracy_, se podría estar sobreestimando el desempeño del modelo. Por lo tanto, es recomendable considerar utilizar otras métricas como _AUC_ o _F1_ para evaluar los modelos obtenidos. Esto será más claro en la sección de evaluación."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo se compone la tasa de atraso por destino, aerolínea, mes del año, día de la semana, temporada, tipo de vuelo?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se muestran algunos gráficos que permiten visualizar la tasa de atraso por destino, aerolínea, mes del año, día de la semana, temporada y tipo de vuelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_delay_ratios(df=data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué variables esperarías que más influyeran en predecir atrasos?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a las variables que esperaría que más influyeran en la predicción de atrasos, algunas opciones podrían ser:\n",
    "- la temporada\n",
    "- el mes del año\n",
    "- el día de la semana\n",
    "- el tipo de vuelo (nacional o internacional)\n",
    "- el destino\n",
    "- la aerolínea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cardinality: int = 25  # 25, 50, 100\n",
    "max_frequency: float = 0.95  # 0.90, 0.95, 0.99\n",
    "\n",
    "# columns to skip in the analysis and reason why\n",
    "skip = {}\n",
    "for col in data.select_dtypes(include=['category', 'number']).columns:\n",
    "    if col in {'atraso_15', 'dif_min'}:\n",
    "        # the target variable, and the feature that is used to create the target variable\n",
    "        reason = 'target variable leakage'\n",
    "    elif col.endswith('-O'):\n",
    "        # operational features are not available at inference time\n",
    "        reason = 'not available at inference time'\n",
    "    elif data[col].nunique() > max_cardinality:\n",
    "        # the number of unique values is too high (high cardinality)\n",
    "        reason = f'too many unique values ({data[col].nunique()})'\n",
    "    elif data[col].value_counts(normalize=True).max() > max_frequency:\n",
    "        # the most frequent value is too frequent (low variance) - constant or near constant feature\n",
    "        reason = f'low variance ({data[col].value_counts(normalize=True).max():3.3%} of the values are the same)'\n",
    "    else:\n",
    "        continue\n",
    "    # add the column to the dictionary with the reason to skip it\n",
    "    skip[col] = reason\n",
    "\n",
    "pprint.pprint(skip, indent=4, width=120, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.select_dtypes(include=['category']).columns:\n",
    "\n",
    "    if col in skip:\n",
    "        print(f'SKIPPING:    {col:15s}  REASON:       {skip[col]:<40}')\n",
    "        continue\n",
    "\n",
    "    print(f'PROCESSING:  {col:15s}  CARDINALITY:  ({data[col].nunique()})')\n",
    "\n",
    "    if 0:\n",
    "        display(\n",
    "            # make a copy of the dataframe to avoid modifying the original one\n",
    "            data.copy(deep=True)\n",
    "            # select the column\n",
    "            # count the number of occurrences of each category\n",
    "            .value_counts(\n",
    "                subset=[col],\n",
    "                normalize=True,\n",
    "                sort=True,\n",
    "                ascending=False,\n",
    "                dropna=False,\n",
    "            )\n",
    "            # rename the column with the category to 'category' (for consistency)\n",
    "            .rename_axis(index={col: 'category'},)\n",
    "            # rename the column with the frequency of each category to 'frequency'\n",
    "            .rename('frequency')\n",
    "            # transform the series into a dataframe\n",
    "            .to_frame()\n",
    "            # style the dataframe\n",
    "            .style\n",
    "            # set table styles\n",
    "            .set_table_styles(TABLE_STYLES)\n",
    "            # set caption\n",
    "            .set_caption(f'Distribution of the column \\'{col}\\' ')\n",
    "            # format the frequency as a percentage\n",
    "            .format({'frequency': '{:.2%}'})\n",
    "            # bar plot\n",
    "            .bar(\n",
    "                subset=['frequency'],\n",
    "                # color='#5fba7d', # red\n",
    "                color='#2b8cbe',  # blue\n",
    "                vmin=0,\n",
    "                vmax=1,\n",
    "            )\n",
    "            # display the table\n",
    "        )\n",
    "\n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "GENERATE_LIGHT_PROFILE_REPORT: bool = False\n",
    "GENERATE_DEEP_PROFILE_REPORT: bool = False\n",
    "\n",
    "tsmode: bool = False  # If True, use time series mode (default: False)\n",
    "sortby: Optional[str] = 'Fecha-I'  # Default: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tsmode:\n",
    "    if sortby is not None:\n",
    "        # if 'tsmode' is True and 'sortby' is not None, then\n",
    "        # set the index to the date column given by the 'sortby' parameter\n",
    "        data = data.set_index(\n",
    "            keys=sortby,\n",
    "            # drop the date column from the dataframe\n",
    "            # to avoid the following error:\n",
    "            #   ValueError(f'{sortby} is both an index level and a column label, which is ambiguous.')\n",
    "            drop=True,\n",
    "            inplace=False,\n",
    "        )\n",
    "\n",
    "        # then, sort the dataframe by the index (the given date column that is now the index) in ascending order\n",
    "        data = data.sort_index(\n",
    "            ascending=True,\n",
    "            axis=0,\n",
    "            inplace=False,\n",
    "        )\n",
    "\n",
    "        # finally, reset the index to a column in the dataframe (drop=False)\n",
    "        data = data.reset_index(\n",
    "            drop=False,  # keep the original index as a column in the dataframe (drop=False)\n",
    "            inplace=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_LIGHT_PROFILE_REPORT:\n",
    "    # with pandas_plotting_backend(backend='matplotlib'):  # NOTE: Handled by the `generate_profile_report` function.\n",
    "    light_profile_report = generate_profile_report(\n",
    "        data=data,\n",
    "        minimal=True,\n",
    "        explorative=False,\n",
    "        # Time Series Configuration\n",
    "        tsmode=tsmode,\n",
    "        sortby=sortby,\n",
    "        # Sampling Configuration\n",
    "        sample_the_dataset=False,\n",
    "        sample_kwargs=None,\n",
    "    )\n",
    "    display(light_profile_report)\n",
    "    # light_profile_report.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_DEEP_PROFILE_REPORT:\n",
    "    # with pandas_plotting_backend(backend='matplotlib'):  # NOTE: Handled by the `generate_profile_report` function.\n",
    "    deep_profile_report = generate_profile_report(\n",
    "        data=data,\n",
    "        minimal=False,\n",
    "        explorative=True,\n",
    "        # Time Series Configuration\n",
    "        tsmode=tsmode,\n",
    "        sortby=sortby,\n",
    "        # Sampling Configuration\n",
    "        sample_the_dataset=False,\n",
    "        sample_kwargs=None,\n",
    "    )\n",
    "    display(deep_profile_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_LIGHT_PROFILE_REPORT:\n",
    "    PATH_TO_LIGHT_PROFILE_REPORT = get_reports_dir_path() / 'light_profile_report.html'\n",
    "    light_profile_report.to_file(output_file=PATH_TO_LIGHT_PROFILE_REPORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_DEEP_PROFILE_REPORT:\n",
    "    PATH_TO_DEEP_PROFILE_REPORT = get_reports_dir_path() / 'deep_profile_report.html'\n",
    "    deep_profile_report.to_file(output_file=PATH_TO_DEEP_PROFILE_REPORT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: transform 'atraso_15' to integer before training to see if AUC plot works\n",
    "# # (now, an error occurs when it tries to operate between numeric and categoric elements)\n",
    "data['atraso_15'] = data['atraso_15'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Any, cast, Dict\n",
    "\n",
    "from pycaret.classification import *\n",
    "\n",
    "from neuralworks.constants import get_assets_dir_path\n",
    "from neuralworks.constants import get_path_to_logs_dir_path\n",
    "from neuralworks.data import get_column_descriptions\n",
    "from neuralworks.report import DatasetMetadata\n",
    "from neuralworks.report import get_default_dataset_metadata\n",
    "from neuralworks.report import get_default_profile_kwargs\n",
    "from neuralworks.report import PandasProfilingReportConfig\n",
    "from neuralworks.report import sample_dataset\n",
    "\n",
    "# https://imbalanced-learn.org/stable/over_sampling.html\n",
    "#\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.over_sampling import ADASYN\n",
    "#\n",
    "# BorderlineSMOTE\n",
    "# SVMSMOTE\n",
    "# KMeansSMOTE\n",
    "#\n",
    "# SMOTENC  # categorical_features\n",
    "# SMOTEN\n",
    "#\n",
    "# https://imbalanced-learn.org/stable/under_sampling.html\n",
    "# https://imbalanced-learn.org/stable/combine.html\n",
    "\n",
    "sample_kwargs = {'frac': 0.1, 'random_state': 42}\n",
    "_ = sample_kwargs.setdefault('frac', 0.1)  # randomly select 10% (0.1) of the rows\n",
    "_ = sample_kwargs.setdefault('random_state', 42)  # set the random state for reproducibility\n",
    "\n",
    "dataset_metadata: DatasetMetadata = get_default_dataset_metadata()\n",
    "# sample the dataset and add it to the dataset metadata dictionary\n",
    "# _ = dataset_metadata.setdefault('sample', sample_dataset(data=data, **sample_kwargs))\n",
    "\n",
    "# tsmode: bool = True  # If True, use time series mode (default: False)\n",
    "# sortby: Optional[str] = 'Fecha-I'  # Default: None\n",
    "minimal: bool = True\n",
    "explorative: bool = True\n",
    "\n",
    "profile_kwargs: PandasProfilingReportConfig = get_default_profile_kwargs()\n",
    "profile_kwargs['dataset'] = dataset_metadata\n",
    "profile_kwargs['minimal'] = minimal\n",
    "profile_kwargs['explorative'] = explorative\n",
    "profile_kwargs['tsmode'] = tsmode\n",
    "profile_kwargs['sortby'] = sortby\n",
    "\n",
    "# NOTE: To disable samples, correlations, missing diagrams and duplicates at once, set them to None\n",
    "# profile_kwargs['samples'] = None\n",
    "# profile_kwargs['correlations'] = None\n",
    "# profile_kwargs['missing_diagrams'] = None\n",
    "# profile_kwargs['duplicates'] = None\n",
    "# profile_kwargs['interactions'] = None\n",
    "\n",
    "target: str = 'atraso_15'  # (unique values:    2)\n",
    "polynomial_features: bool = False\n",
    "\n",
    "# setup the environment\n",
    "clf = setup(\n",
    "    # copy the data to avoid side effects\n",
    "    data=data.copy(deep=True),  # TRAIN DATA\n",
    "    target=target,\n",
    "    index=False,\n",
    "    train_size=0.8,\n",
    "    #\n",
    "    # ordinal_features=None,\n",
    "    ordinal_features={\n",
    "        # original features\n",
    "        'DIA': list(range(1, 31 + 1)),\n",
    "        'MES': list(range(1, 12 + 1)),\n",
    "        'AÑO': list(range(2017, 2018 + 1)),\n",
    "        'DIANOM': ['Lunes', 'Martes', 'Miercoles', 'Jueves', 'Viernes', 'Sabado', 'Domingo'],\n",
    "        # synthetic features\n",
    "        'periodo_dia': ['mañana', 'tarde', 'noche'],\n",
    "    },\n",
    "    #\n",
    "    # numeric_features=None,\n",
    "    # numeric_features=[\n",
    "    #     'dif_min',  # target leakage, because it ('dif_min') is a function of the target variable ('atraso_15')\n",
    "    # ],\n",
    "    #\n",
    "    # categorical_features=None,\n",
    "    categorical_features=[\n",
    "        # original features\n",
    "        'DIA',\n",
    "        'MES',\n",
    "        'AÑO',\n",
    "        'DIANOM',\n",
    "        #\n",
    "        'TIPOVUELO',  # (unique values:  2)\n",
    "        'OPERA',  # high cardinality (unique values: 23)  # TODO: CHECK THIS VARIABLE\n",
    "        'SIGLADES',  # high cardinality (unique values: 62)  # TODO: CHECK THIS VARIABLE\n",
    "        #\n",
    "        # synthetic features\n",
    "        'periodo_dia',\n",
    "        'temporada_alta',  # (unique values:    2)\n",
    "    ],\n",
    "    #\n",
    "    # date_features=None,\n",
    "    # date_features=[\n",
    "    #     'Fecha-I',  # using 'DIA', 'MES', 'AÑO', 'periodo_dia' features instead  # TODO: VERIFY THIS\n",
    "    #     'Fecha-O',  # Not available at inference time  # target leakage (the target variable is calculated using this feature)\n",
    "    # ],\n",
    "    #\n",
    "    # text_features=None,\n",
    "    #\n",
    "    # ignore_features=None,\n",
    "    ignore_features=[\n",
    "        # original features\n",
    "        #\n",
    "        'Fecha-I',  # using 'DIA', 'MES', 'AÑO', 'periodo_dia' features instead     # TODO: VERIFY THIS\n",
    "        #\n",
    "        'Vlo-I',  # high cardinality feature     (unique values:  584)\n",
    "        'Ori-I',  # low  variance    feature     (unique values:    1)\n",
    "        'Des-I',  # (unique values:   64) - Using 'SIGLADES' instead\n",
    "        'Emp-I',  # (unique values:   30) - Using 'OPERA' instead\n",
    "        #\n",
    "        'Fecha-O',  # Not available at inference time | target leakage (the target variable is calculated using this feature)\n",
    "        #\n",
    "        'Vlo-O',  # not available at inference time (unique values:  861)\n",
    "        'Ori-O',  # not available at inference time (unique values:    1)  # low  variance   feature\n",
    "        'Des-O',  # not available at inference time (unique values:   63)\n",
    "        'Emp-O',  # not available at inference time (unique values:   32)\n",
    "        #\n",
    "        'SIGLAORI',  # low  variance   feature     (unique values:    1)\n",
    "        #\n",
    "        # synthetic features\n",
    "        'dif_min',  # target leakage (the target variable is calculated using this feature)\n",
    "    ],\n",
    "    #\n",
    "    # keep_features=None,\n",
    "    #\n",
    "    # create_date_columns=[\n",
    "    #     # 'day',\n",
    "    #     'month',\n",
    "    #     'year',\n",
    "    # ]\n",
    "    #\n",
    "    imputation_type='simple',\n",
    "    numeric_imputation='mean',\n",
    "    categorical_imputation='mode',\n",
    "    #\n",
    "    polynomial_features=polynomial_features,\n",
    "    polynomial_degree=2,\n",
    "    #\n",
    "    low_variance_threshold=0.01,  # Default: None\n",
    "    #\n",
    "    # group_features=None,\n",
    "    # group_names=None,\n",
    "    #\n",
    "    remove_multicollinearity=True,\n",
    "    multicollinearity_threshold=0.9,\n",
    "    #\n",
    "    # bin_numeric_features=None,\n",
    "    #\n",
    "    remove_outliers=True,  # if True, removes outliers using an Isolation Forest.\n",
    "    outliers_method='iforest',  # 'iforest' (IsolationForest), 'ee' (EllipticEnvelope), 'lof' (LocalOutlierFactor)\n",
    "    outliers_threshold=0.05,  # percentage of outliers to be removed (default=0.05)\n",
    "    #\n",
    "    # IMBALANCE\n",
    "    fix_imbalance=True,  # If set to True, uses SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "    fix_imbalance_method='SMOTE',\n",
    "    #\n",
    "    transformation=True,  # If set to True, it applies the power transform to make data more Gaussian-like.\n",
    "    transformation_method='yeo-johnson',  # 'yeo-johnson' (Box-Cox transform), 'quantile' (Quantile transform)\n",
    "    #\n",
    "    normalize=True,\n",
    "    normalize_method='zscore',  # 'minmax', 'maxabs', 'robust', 'zscore'\n",
    "    #\n",
    "    # pca=True,  # If set to True, it applies PCA to reduce the dimensionality of the data.\n",
    "    # pca_method='linear',  # 'linear', 'kernel', 'incremental'\n",
    "    # pca_components='mle',  # number of components to keep, 'mle' (Minka's MLE)\n",
    "    #\n",
    "    feature_selection=False,  # <<<------------------------------------------------------\n",
    "    # 'univariate' (SelectKBest) 'classic' (SelectFromModel) 'sequential' (SequentialFeatureSelector)\n",
    "    feature_selection_method='classic',\n",
    "    feature_selection_estimator='lightgbm',\n",
    "    # TODO: VERIFY THIS <<<------------------------------------------------------\n",
    "    n_features_to_select=0.2,  # Default=0.2 (20% of features) - Old default: 10\n",
    "    #\n",
    "    data_split_shuffle=True,  # if True, shuffles the data before splitting\n",
    "    # data_split_stratify=True,  # if True, stratify the data based on the \"target\" column\n",
    "    data_split_stratify=[\n",
    "        # 'DIA',\n",
    "        # 'MES',\n",
    "        # 'AÑO',\n",
    "        # 'DIANOM',\n",
    "        'TIPOVUELO',\n",
    "        # 'OPERA',\n",
    "        # 'SIGLADES',\n",
    "        # 'periodo_dia',\n",
    "        'temporada_alta',\n",
    "        # target column\n",
    "        'atraso_15'\n",
    "    ],\n",
    "    #\n",
    "    fold_strategy='stratifiedkfold',  # 'kfold', 'stratifiedkfold', 'groupkfold', 'timeseries',  custom CV generator \n",
    "    fold=5,  # number of folds in a CV setup (default=10)\n",
    "    fold_shuffle=True,  # if True, shuffles the data before splitting into folds (default=False)\n",
    "    # fold_groups=None,\n",
    "    #\n",
    "    n_jobs=-1,\n",
    "    #\n",
    "    session_id=123,\n",
    "    system_log=str(get_path_to_logs_dir_path() / f'{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}_pycaret.log'),\n",
    "    log_experiment='mlflow',\n",
    "    experiment_name=f'{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}_pycaret_experiment',\n",
    "    log_plots=True,  # to log plots in mlflow\n",
    "    log_profile=True,  # to log data profile in mlflow\n",
    "    log_data=True,  # to log dataset in mlflow\n",
    "    #\n",
    "    profile=True,  # INTERACTIVE EDA REPORT - does not work in vscode\n",
    "    profile_kwargs=cast(Dict[str, Any], profile_kwargs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a terminal, run:\n",
    "#   cd \"${HOME}/Documents/GitHub/latam/notebooks\" && mlflow ui\n",
    "\n",
    "# https://www.mlflow.org/docs/latest/tracking.html#storage\n",
    "# ['postgresql', 'mysql', 'sqlite', 'mssql']\n",
    "# mlflow ui --backend-store-uri sqlite:///mlruns.db --host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: exclude catboost since it is too slow, and has poor performance?\n",
    "clf.models()[clf.models()['Turbo']]['Name'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature names: ['x0', 'x1', ..., 'x(n_features - 1)']\n",
    "{i: c for i, c in enumerate(clf.dataset.columns.to_list())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(clf.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycaret\n",
    "import pycaret.internal\n",
    "import pycaret.internal.pipeline\n",
    "\n",
    "pipeline = pycaret.internal.pipeline.Pipeline(steps=clf.pipeline.steps[0:5], verbose=False)\n",
    "display(pipeline)\n",
    "\n",
    "# X is the data dataframe without the target column\n",
    "X = data.copy(deep=True).drop(columns=[target])\n",
    "# y is the target column\n",
    "y = data.copy(deep=True)[target]\n",
    "\n",
    "# (n_samples, n_transformed_features)\n",
    "(Xt, yt) = pipeline.fit_transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Xt), len(Xt), type(Xt), type(yt), len(Xt), len(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Xt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xt[['Des-I', 'OPERA_K.L.M.']]\n",
    "\n",
    "# Ori-I OPERA_Iberia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial_features: bool, default = False\n",
    "# When set to True, new features are created based on all polynomial combinations that exist within the numeric features in a dataset to the degree defined in polynomial_degree param.\n",
    "\n",
    "# polynomial_degree: int, default = 2\n",
    "# Degree of polynomial features. For example, if an input sample is two dimensional and of the form [a, b], the polynomial features with degree = 2 are: [1, a, b, a^2, ab, b^2].\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "\n",
    "dataset_transformed = clf.dataset_transformed.copy(deep=True)\n",
    "dataset_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if polynomial_features:\n",
    "    # map transformed column names\n",
    "    # # feature names: ['x0', 'x1', ..., 'x(n_features - 1)']\n",
    "    m = {str(i): c for i, c in enumerate(Xt.columns.to_list())}\n",
    "    display(m)\n",
    "\n",
    "    for c in dataset_transformed.columns.to_list():\n",
    "        if c not in [target]:\n",
    "            v = c.replace('x', '').split(' ')\n",
    "\n",
    "            if len(v) == 1:\n",
    "                print(c, '     -----> ', m[v[0]])\n",
    "\n",
    "            if len(v) == 2:\n",
    "                print(c, ' -----> ', m[v[0]], ' * ', m[v[1]])\n",
    "\n",
    "            print()\n",
    "\n",
    "    # Des-I\n",
    "    # OPERA_K.L.M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transformed.corr('pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Pearson product-moment correlation coefficient (standard correlation coefficient)\n",
    "# https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
    "sns.heatmap(\n",
    "    # Compute pairwise correlation of columns, excluding NA/null values.\n",
    "    data=dataset_transformed.corr(method='pearson'),\n",
    "    annot=True,\n",
    "    fmt='.3f',\n",
    "    cmap='coolwarm',  # set the color map\n",
    "    # cmap='RdBu_r',  # set the color map\n",
    "    cbar=True,  # set the color bar\n",
    "    cbar_kws={'label': 'Pearson correlation coefficient'},\n",
    "    vmin=-1,  # set the minimum value for the color map\n",
    "    vmax=1,  # set the maximum value for the color map\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    'Pearson correlation coefficient matrix of variables',\n",
    "    fontsize=25,\n",
    "    fontweight='bold',\n",
    "    pad=20,\n",
    ")\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# La elección de la Métrica de evaluación más apropiada, dependerá del caso de uso\n",
    "# La elección del Modelo dependerá del caso de uso\n",
    "\n",
    "# Alta Precision se relaciona con una tasa baja de falsos positivos\n",
    "\n",
    "# Alto Recall se relaciona con una baja tasa de falsos negativos.\n",
    "# lo que significa que el modelo será más conservador en sus predicciones\n",
    "# (es decir, será más probable que prediga un 0 cuando el valor verdadero es 1)\n",
    "\n",
    "# Recall    - cuando la detección de la verdad es de suma importancia.\n",
    "#     Ejemplo: La predicción del cáncer,\n",
    "#              aquí la declaración del problema requiere que se minimicen los falsos negativos,\n",
    "#              lo que implica que se maximice el Recall y Sensitivity (true positive rate)\n",
    "\n",
    "# Precision - cuando no tener una gran cantidad de falsos positivos de suma importancia\n",
    "#     Ejemplo: La detección de spam,\n",
    "#              un falso positivo sería una observación que no era spam pero que nuestro modelo de clasificación clasificó como spam\n",
    "#\n",
    "#     Alta Precision se relaciona con una tasa baja de falsos positivos,\n",
    "#     lo que significa que el modelo será más conservador en sus predicciones\n",
    "\n",
    "# high precision relates to the low false positive rate,\n",
    "# high recall relates to the low false negative rate,\n",
    "# and high F-beta score relates to both.\n",
    "\n",
    "# The highest possible value of an F-score is 1.0, indicating perfect precision and recall,\n",
    "# and the lowest possible value is 0, if both precision and recall are zero.deep_profile_report\n",
    "\n",
    "# F1 gives importance to both Recall and Precision.\n",
    "\n",
    "# Kappa is a good metric for imbalanced dataset\n",
    "# it takes into account the possibility of the agreement occurring by chance.\n",
    "\n",
    "# The Kappa statistic (or value) is a metric that compares an Observed Accuracy with an Expected Accuracy (random chance).\n",
    "# Kappa = (observed accuracy - expected accuracy)/(1 - expected accuracy)\n",
    "\n",
    "# Landis and Koch considers 0-0.20 as slight, 0.21-0.40 as fair, 0.41-0.60 as moderate, 0.61-0.80 as substantial, and 0.81-1 as almost perfect.\n",
    "# Fleiss considers kappas > 0.75 as excellent, 0.40-0.75 as fair to good, and < 0.40 as poor.\n",
    "\n",
    "# We use Kappa for selecting a best suited model type and hyperparametrization amongst multiple choices for our very imbalanced problem\n",
    "\n",
    "# https://stats.stackexchange.com/questions/82162/cohens-kappa-in-plain-english\n",
    "# https://stats.stackexchange.com/questions/222558/classification-evaluation-metrics-for-highly-imbalanced-data\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn-metrics-balanced-accuracy-score\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# NOTE: Bagging  is used as a way to reduce the variance          of a black-box estimator\n",
    "# https://pycaret.gitbook.io/docs/get-started/functions/optimize#method-bagging\n",
    "\n",
    "# NOTE: Boosting is used as a way to reduce the bias and variance of a black-box estimator\n",
    "# https://pycaret.gitbook.io/docs/get-started/functions/optimize#method-boosting\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# A Bagging classifier is an ensemble meta-estimator\n",
    "# that fits base classifiers each on random subsets of the original dataset\n",
    "# and then aggregate their individual predictions (either by voting or by averaging)\n",
    "# to form a final prediction.\n",
    "#\n",
    "# Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator\n",
    "# (e.g., a decision tree), by introducing randomization into its construction procedure\n",
    "# and then making an ensemble out of it.\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier\n",
    "\n",
    "# The idea behind the VotingClassifier is to combine conceptually different machine learning classifiers\n",
    "# and use a majority vote or the average predicted probabilities (soft vote) to predict the class labels.\n",
    "# Such a classifier can be useful for a set of equally well performing models in order to balance out\n",
    "# their individual weaknesses.\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# https://pycaret.gitbook.io/docs/get-started/functions/optimize#changing-the-method\n",
    "\n",
    "# When method = 'soft', it predicts the class label based on the argmax of the sums of the predicted\n",
    "# probabilities, which is recommended for an ensemble of well-calibrated classifiers\n",
    "\n",
    "# When the method = 'hard' , it uses the predictions (hard labels) from input models instead of probabilities.\n",
    "\n",
    "# The default method is set to auto which means it will try to use soft method\n",
    "# and fall back to hard if the former is not supported,\n",
    "# this may happen when one of your input models does not support predict_proba attribute.\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# https://pycaret.gitbook.io/docs/get-started/functions/optimize#changing-the-weights\n",
    "\n",
    "# By default, all the input models are given equal weight when blending them\n",
    "# but you can explicitly pass the weights to be given to each input model.\n",
    "# Example: blender_weighted = blend_models([lr,dt,knn], weights = [0.5,0.2,0.3])\n",
    "\n",
    "# You can also tune the weights of the blender using the tune_model\n",
    "# # blender_weighted = blend_models([lr,dt,knn], weights = [0.5,0.2,0.3])\n",
    "# # tuned_blender = tune_model(blender_weighted)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/ensemble.html#stacked-generalization\n",
    "\n",
    "# Stacked generalization is a method for combining estimators to reduce their biases\n",
    "# The predictions of each individual estimator are stacked together and used as input\n",
    "# to a final estimator to compute the prediction. This final estimator is trained through cross-validation.\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: 'Kappa' is a good classification metric for highly imbalanced datasets.\n",
    "# https://stats.stackexchange.com/questions/222558/classification-evaluation-metrics-for-highly-imbalanced-data\n",
    "\n",
    "# Number of top_n models to return. For example, to select top 3 models use n_select = 3.\n",
    "n_select = 3\n",
    "\n",
    "# Metric to sort the models by.\n",
    "sort_by = 'Kappa'  # 'Accuracy', 'AUC', 'Recall', 'Precision', 'F1', 'Kappa', 'MCC'\n",
    "\n",
    "# Metric to use for model selection.\n",
    "# optimize_metric = 'Kappa'  # 'Accuracy', 'AUC', 'Recall', 'Precision', 'F1', 'Kappa', 'MCC'\n",
    "\n",
    "# optimize_metric = 'Accuracy'\n",
    "# optimize_metric = 'AUC'  # -----------------------------> AUC\n",
    "# optimize_metric = 'Recall'\n",
    "# optimize_metric = 'Precision'\n",
    "optimize_metric = 'F1'  # ----------------------------> F1\n",
    "# optimize_metric = 'Kappa'\n",
    "# optimize_metric = 'MCC'\n",
    "\n",
    "# The search library used for tuning hyperparameters.\n",
    "search_library = 'scikit-optimize'  # 'scikit-learn' (default), 'scikit-optimize', 'tune-sklearn', 'optuna'\n",
    "# search_library = 'tune-sklearn'  # 'scikit-learn' (default), 'scikit-optimize', 'tune-sklearn', 'optuna'\n",
    "\n",
    "if search_library == 'scikit-learn':\n",
    "    # - 'random'        : random grid search (default)\n",
    "    # - 'grid'          : grid search\n",
    "    search_algorithm = 'random'\n",
    "if search_library == 'scikit-optimize':\n",
    "    # - 'bayesian'      : Bayesian search (default)\n",
    "    search_algorithm = 'bayesian'\n",
    "elif search_library == 'tune-sklearn':\n",
    "    # - 'random'        : random grid search (default)\n",
    "    # - 'grid'          : grid search\n",
    "    # - 'bayesian'      : ``pip install scikit-optimize``\n",
    "    # - 'hyperopt'      : ``pip install hyperopt``\n",
    "    # - 'optuna'        : ``pip install optuna``\n",
    "    # - 'bohb'          : ``pip install hpbandster ConfigSpace``\n",
    "    # search_algorithm = 'random'\n",
    "    search_algorithm = 'bayesian'\n",
    "elif search_library == 'optuna':\n",
    "    # - 'random'        : randomized search\n",
    "    # - 'tpe'           : Tree-structured Parzen Estimator search (default)\n",
    "    search_algorithm = 'tpe'\n",
    "else:\n",
    "    search_algorithm = None  # default: None\n",
    "\n",
    "# TODO: Consider using Early Stopping for Tuning\n",
    "\n",
    "# early_stopping: bool or str or object, default = False\n",
    "#     Use early stopping to stop fitting to a hyperparameter configuration\n",
    "#     if it performs poorly. Ignored when ``search_library`` is scikit-learn,\n",
    "#     or if the estimator does not have 'partial_fit' attribute. If False or\n",
    "#     None, early stopping will not be used. Can be either an object accepted\n",
    "#     by the search library or one of the following:\n",
    "\n",
    "#     - 'asha' for Asynchronous Successive Halving Algorithm\n",
    "#     - 'hyperband' for Hyperband\n",
    "#     - 'median' for Median Stopping Rule\n",
    "#     - If False or None, early stopping will not be used.\n",
    "\n",
    "# early_stopping_max_iters: int, default = 10\n",
    "#     Maximum number of epochs to run for each sampled configuration.\n",
    "#     Ignored if ``early_stopping`` is False or None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the performance of all models\n",
    "topk = compare_models(\n",
    "    cross_validation=True,\n",
    "    sort=sort_by,\n",
    "    n_select=n_select,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# get the scoring grid of the top k models\n",
    "topk_results: pd.DataFrame = pull()  # .reset_index(drop=True)\n",
    "\n",
    "# ['Model', 'Accuracy', 'AUC', 'Recall', 'Prec.', 'F1', 'Kappa', 'MCC', 'TT (Sec)']\n",
    "# topk_results.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check if increasing the n_iter is helpful or not (e.g., n_iter = 50)\n",
    "\n",
    "# TODO: Check if setting choose_better = True is more appropiate\n",
    "# https://pycaret.gitbook.io/docs/get-started/functions/optimize#automatically-choose-better\n",
    "# When set to True it will always return a better performing model\n",
    "# meaning that if hyperparameter tuning doesn't improve the performance,\n",
    "# it will return the input model.\n",
    "\n",
    "# https://pycaret.readthedocs.io/en/latest/api/classification.html#pycaret.classification.tune_model\n",
    "tuned_topk = [\n",
    "    tune_model(\n",
    "        i,\n",
    "        optimize=optimize_metric,\n",
    "        search_library=search_library,\n",
    "        # choose_better=True,\n",
    "        n_iter=50,  # <<<------------------------------------------------------\n",
    "    ) for i in topk\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check if increasing the n_estimators is helpful or not  (e.g., n_estimators = 100)\n",
    "\n",
    "# TODO: Check if setting choose_better = True is more appropiate\n",
    "# https://pycaret.gitbook.io/docs/get-started/functions/optimize#automatically-choose-better-1\n",
    "# When set to True it will always return a better performing model\n",
    "# meaning that if hyperparameter tuning doesn't improve the performance,\n",
    "# it will return the input model.\n",
    "\n",
    "# ensembled_topk\n",
    "bagged_topk = [\n",
    "    ensemble_model(\n",
    "        i,\n",
    "        method='Bagging',\n",
    "        optimize=optimize_metric,\n",
    "        # choose_better=True,\n",
    "        n_estimators=100,  # <<<------------------------------------------------------\n",
    "    ) for i in tuned_topk  # topk\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check if setting choose_better = True is more appropiate\n",
    "# https://pycaret.gitbook.io/docs/get-started/functions/optimize#automatically-choose-better-2\n",
    "# When set to True it will always return a better performing model\n",
    "# meaning that if hyperparameter tuning doesn't improve the performance,\n",
    "# it will return the input model.\n",
    "\n",
    "# This function trains a Soft Voting / Majority Rule classifier for select models\n",
    "blender = blend_models(\n",
    "    tuned_topk,  # topk,  # TODO: CHECK THIS\n",
    "    optimize=optimize_metric,\n",
    "    # choose_better=True,\n",
    "    weights=[1.0 / len(tuned_topk)] * len(tuned_topk),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check if increasing the n_iter is helpful or not (e.g., n_iter = 50)\n",
    "\n",
    "# TODO: Check if setting choose_better = True is more appropiate\n",
    "# https://pycaret.gitbook.io/docs/get-started/functions/optimize#automatically-choose-better\n",
    "# When set to True it will always return a better performing model\n",
    "# meaning that if hyperparameter tuning doesn't improve the performance,\n",
    "# it will return the input model.\n",
    "\n",
    "tuned_blender = tune_model(\n",
    "    blender,\n",
    "    optimize=optimize_metric,\n",
    "    search_library=search_library,\n",
    "    search_algorithm=search_algorithm,\n",
    "    # choose_better=True,\n",
    "    n_iter=50,  # <<<------------------------------------------------------\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check setting method = 'auto' explicitly\n",
    "# https://pycaret.gitbook.io/docs/get-started/functions/optimize#changing-the-method-1\n",
    "\n",
    "# TODO: Check setting the meta_model explicitly\n",
    "# train meta-model\n",
    "# meta_model = create_model('lightgbm')\n",
    "\n",
    "# TODO: Check setting restack = False or not\n",
    "# https://pycaret.gitbook.io/docs/get-started/functions/optimize#restacking\n",
    "\n",
    "stacker = stack_models(\n",
    "    tuned_topk,  # topk,  # TODO: CHECK THIS\n",
    "    optimize=optimize_metric,\n",
    "    # method='auto',\n",
    "    # meta_model=meta_model,\n",
    "    # restack=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = automl(optimize=optimize_metric)\n",
    "display(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_check(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function analyzes the predictions generated from a trained model.\n",
    "# Most plots in this function are implemented based on the SHAP (Shapley Additive exPlanations).\n",
    "# For more info on this, please see https://shap.readthedocs.io/en/latest/\n",
    "try:\n",
    "    interpret_model(best_model)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'base value' is defined as the mean predicted target\n",
    "# f(x) is the prediction for a selected observation\n",
    "# The red-colored  features increased the predicted value\n",
    "# The blue-colored features decreased the predicted value\n",
    "# The size of each feature indicates the impact it has on the model\n",
    "try:\n",
    "    interpret_model(best_model, plot='reason')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    interpret_model(best_model, plot='correlation')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate model\n",
    "calibrated = calibrate_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(calibrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize threshold\n",
    "calibrated_threshold_optimized = optimize_threshold(calibrated)\n",
    "# display(calibrated_threshold_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(calibrated_threshold_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize threshold\n",
    "threshold_optimized = optimize_threshold(best_model)\n",
    "display(threshold_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(threshold_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard = get_leaderboard(finalize_models=False, model_only=False)\n",
    "display(leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sorted\n",
    "display(\n",
    "    # copy\n",
    "    leaderboard.copy(deep=True)\n",
    "    # drop\n",
    "    .drop(columns=['Model'])\n",
    "    # sort\n",
    "    .sort_values(\n",
    "        by=[\n",
    "            'Kappa',\n",
    "            'F1',\n",
    "            'Prec.',\n",
    "            'Recall',\n",
    "            'AUC',\n",
    "            'MCC',\n",
    "            'Accuracy',\n",
    "        ],\n",
    "        ascending=False,\n",
    "    )\n",
    "    # top\n",
    "    .head(50)\n",
    "    # display\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    # copy\n",
    "    leaderboard.copy(deep=True)\n",
    "    # drop\n",
    "    .drop(columns=['Model'])\n",
    "    # descriptive stats\n",
    "    .describe()\n",
    "    # transpose\n",
    "    .T\n",
    "    # reorder\n",
    "    .reindex([\n",
    "        'Kappa',\n",
    "        'F1',\n",
    "        'Prec.',\n",
    "        'Recall',\n",
    "        'AUC',\n",
    "        'MCC',\n",
    "        'Accuracy',\n",
    "    ])\n",
    "    # display\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzes the performance of a trained model on holdout set.\n",
    "\n",
    "#   List of available plots (ID - Name):\n",
    "#\n",
    "#       * 'pipeline'            - Schematic drawing of the preprocessing pipeline\n",
    "#       * 'auc'                 - Area Under the Curve\n",
    "#       * 'threshold'           - Discrimination Threshold\n",
    "#       * 'pr'                  - Precision Recall Curve\n",
    "#       * 'confusion_matrix'    - Confusion Matrix\n",
    "#       * 'error'               - Class Prediction Error\n",
    "#       * 'class_report'        - Classification Report\n",
    "#       * 'boundary'            - Decision Boundary\n",
    "#       * 'rfe'                 - Recursive Feature Selection\n",
    "#       * 'learning'            - Learning Curve\n",
    "#       * 'manifold'            - Manifold Learning\n",
    "#       * 'calibration'         - Calibration Curve\n",
    "#       * 'vc'                  - Validation Curve\n",
    "#       * 'dimension'           - Dimension Learning\n",
    "#       * 'feature'             - Feature Importance\n",
    "#       * 'feature_all'         - Feature Importance (All)\n",
    "#       * 'parameter'           - Model Hyperparameter\n",
    "#       * 'lift'                - Lift Curve\n",
    "#       * 'gain'                - Gain Chart\n",
    "#       * 'tree'                - Decision Tree\n",
    "#       * 'ks'                  - KS Statistic Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    for model in topk:\n",
    "        display(model)\n",
    "\n",
    "if 0:\n",
    "    for model in topk:\n",
    "        try:\n",
    "            plot_model(model, plot='auc')  # Area Under the Curve\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "if 0:\n",
    "    for model in topk:\n",
    "        try:\n",
    "            # https://www.scikit-yb.org/en/latest/api/classifier/confusion_matrix.html#yellowbrick.classifier.confusion_matrix.ConfusionMatrix\n",
    "            plot_model(\n",
    "                model,\n",
    "                plot='confusion_matrix',\n",
    "                plot_kwargs={'percent': True},\n",
    "            )  # Confusion Matrix\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "if 0:\n",
    "    for model in topk:\n",
    "        try:\n",
    "            plot_model(model, plot='error')  # Class Prediction Error\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "if 0:\n",
    "    for model in topk:\n",
    "        try:\n",
    "            # https://www.scikit-yb.org/en/latest/api/classifier/classification_report.html#yellowbrick.classifier.classification_report.ClassificationReport\n",
    "            plot_model(\n",
    "                model,\n",
    "                plot='class_report',\n",
    "            )  # Classification Report\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "if 0:\n",
    "    for model in topk:\n",
    "        try:\n",
    "            plot_model(model, plot='feature')  # feature importance\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "if 1:\n",
    "    for model in topk:\n",
    "        try:\n",
    "            plot_model(model, plot='feature_all')  # feature importance (all)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "if 0:\n",
    "    for model in topk:\n",
    "        try:\n",
    "            # https://www.scikit-yb.org/en/latest/api/classifier/threshold.html#yellowbrick.classifier.threshold.DiscriminationThreshold\n",
    "            plot_model(model, plot='threshold')  # Discrimination Threshold\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "if 0:\n",
    "    for model in topk:\n",
    "        try:\n",
    "            plot_model(model, plot='parameter')  # Model Hyperparameter\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "# for model in tuned_topk:\n",
    "#     display(model)\n",
    "\n",
    "# for model in bagged_topk:\n",
    "#     display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    # NOTE: This is being very slow and it is not clear if it is worth it yet\n",
    "    # optimizes the probability threshold for a trained model\n",
    "    # https://pycaret.gitbook.io/docs/get-started/functions/optimize#optimize_threshold\n",
    "    best_model_threshold = optimize_threshold(\n",
    "        best_model,\n",
    "        optimize=optimize_metric,\n",
    "        grid_interval=0.1,  # NOTE: This should be 10 iterations\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    final_model = finalize_model(best_model)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpret_model\n",
    "# calibrate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the target column of the test dataset\n",
    "# predictions = predict_model(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "save_model(model=best_model, model_name='my_best_pipeline')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "7941d958afc4cea9bfd6acbb3a7bac6fbc10ee3bebf87c614e5e4d4a93d66f04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
